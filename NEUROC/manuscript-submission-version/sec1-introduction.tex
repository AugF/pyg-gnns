\section{Introduction}

In recent years, the graph neural network (GNN) becomes a hot research topic in the field of artificial intelligence.
%
Many GNNs~\cite{kipf2017_gcn, defferrad2016_chebnet, li2018_agcn,li2015_ggnn, hamilton2017_graphsage, huang2018_gat, zhang2018_gaan} are proposed.
%
They can learn the representation of vertices/edges in a graph from its topology and the original feature vectors in an \emph{end-to-end} manner.
%
The powerful expression capability makes GNNs achieve good accuracy in not only graph analytical tasks \cite{zhou2018_gnn_review, zhang2018_gnn_survey, comprehensive-survey-wu-2020} (like node classification and link prediction) but also computer vision tasks (like human-object interaction \cite{qi2018_learning_humanobject}, human parsing \cite{wang2020_hierarchical_human_parsing}, and video object segmentation \cite{wang2019_zeroshot_video}).

To train GNNs easily, a series of GNN libraries/systems \cite{PyG, DGL, ma2019_neugraph, zhu2019_aligraph, PGL} are proposed.
%
PyTorch Geometric (PyG) \cite{PyG}, NeuGraph \cite{ma2019_neugraph}, PGL \cite{PGL} and Deep Graph Library (DGL) \cite{DGL} build upon the existing deep learning frameworks (PyG on PyTorch, NeuGraph on TensorFlow, PGL on PaddlePaddle, DGL on multiple backends).
%
They provide users with a high-level programming model (the message-passing framework for PyG/PGL/DGL and the SAGA-NN model for NeuGraph) to describe the structure of a GNN.
%
They take advantage of the common tools provided by the underlying frameworks like the automatic differentiation to simplify the development.
%
They utilize specially optimized CUDA kernels (like kernel fusion \cite{DGL, ma2019_neugraph}) and other implementation techniques (like 2D graph partitioning \cite{ma2019_neugraph}) to improve the speed of GNN training on GPUs.

However, what is the real performance bottleneck in GNN training and inference is still in doubt.
%
Yan et al. \cite{yan2020_characterizing_gcn} and Zhang et al. \cite{zhang2020_analysis_neugraph} experimentally analyze the architectural characteristics of GNN \emph{inference}.
%
They find that the GNN inference is more cache-friendly than the traditional graph analysis tasks (like PageRank) and is suitable for GPUs.
%
They verify the effectiveness of the kernel fusion optimization in reducing the time of inference.
%
Nevertheless, they only analyze the inference stage, ignoring the effects of the backpropagation during training.

To explore essential performance bottlenecks in both GNN training and inference, we conduct a range of experimental analysis in this work.
%
We focus on the efficiency bottlenecks of GNN training and inference.
%
We model the GNNs with the message-passing framework that decomposes a GNN layer into two parts: the vertex calculation and the edge calculation.
%
According to the time complexity of the two parts, we classify the typical GNNs into four quadrants (\{high, low\} complexity $\times$ \{vertex, edge\} calculation).
%
We choose GCN \cite{kipf2017_gcn}, GGNN \cite{li2015_ggnn}, GAT \cite{huang2018_gat}, and GaAN \cite{zhang2018_gaan} as representative GNNs of the four quadrants.

We implement them with PyG and evaluate their efficiency and accuracy with six real-world datasets on a GPU card.
%
We identify the most time-consuming stage in GNN training and inference by decomposing the training and inference time per epoch from the layer level to the operator level.
%
We also analyze the memory usage during training and inference to discover the main factor that limits the data scalability of GNN training and inference on GPUs. 
%
Finally, we evaluate whether or not the sampling techniques affect the performance bottlenecks and accuracy.
%
The key findings and insights are summarized below.

\begin{itemize}
    \item \emph{The training and inference time and the memory usage of a GNN layer are mainly affected by the dimensions of the input/output hidden vectors.}
    %
    Fixing other hyper-parameters, the training and inference time and the memory usage of a GNN layer increase linearly with the dimensions.
    
    \item \emph{The edge-related calculation is the performance bottleneck for most GNNs.}
    For GNNs with high edge calculation complexity, most of the training and inference time is spent on conducting the messaging function for every edge.
    %
    For GNNs with low edge calculation complexity, the collection and aggregation of message vectors of all edges consume most of the training and inference time.
    
    \item \emph{The high memory usage of the edge calculation stage is the main factor limiting the data scalability of GNN training and inference.}
    %
    The edge calculation generates (and caches) many intermediate results.
    %
    They are an order of magnitude larger than the dataset itself.
    %
    As GPUs have limited on-chip memory, high memory consumption prevents us from performing training and inference on big graphs.
    
    \item \emph{The sampling techniques can significantly reduce the memory usage of training and inference.}
    %
    The sampling techniques are essential for performing GNN training and inference on big graphs with GPUs.
    %
    The accuracy of the GNN models trained with the sampling techniques is close to the accuracy of full-batch training.
    %
    However, the existing implementation of sampling is still inefficient.
    % 
    The time spent on sampling may exceed the time spent on training and inference.
    Under small batch sizes, the sampled graphs are also small, wasting the computing power of GPUs.
\end{itemize}

Based on the insights, we provide several potential optimization directions:

\begin{itemize}
      \item To reduce training and inference time, \emph{optimizations should focus on improving the efficiency of the edge calculation}.
      % 
      One may consider developing optimized operators for the messaging step that is the major source of computing costs in the edge calculation.
      %
       Fusing operators of the collection step, messaging function and the aggregation step together is another way to reduce the overheads in the edge calculation.
       
      \item To reduce memory usage, \emph{optimizations should focus on reducing the intermediate results in the edge calculation}.
      %
      One may consider adopting the checkpoint mechanism to cache less intermediate results during the forward phase and re-calculate the needed data on the fly during the backpropagation.
      %
      \item To improve the efficiency of the sampling techniques, \emph{one may consider overlapping the sampling on the CPU side with the training/inference on the GPU side.}
      %
      Choosing a proper batch size automatically is another potential optimization.
\end{itemize}

We hope that our analysis can help the developers of the GNN libraries/systems have a better understanding of the characteristics of GNN training/inference and propose more targeted optimizations.

\paragraph{Outline}
We briefly survey the typical GNNs in Section~\ref{sec:review_of_gnns}.
%
We introduce our experimental setting and targets in Section~\ref{sec:experimental_design}.
%
The experimental results are presented and analyzed in Section~\ref{sec:experiment_results}.
%
We summarize the key findings and give out potential optimization directions in Section~\ref{sec:insights}.
%
We introduce the related work in Section~\ref{sec:related_work} and conclude our work in Section~\ref{sec:conclusion}.
