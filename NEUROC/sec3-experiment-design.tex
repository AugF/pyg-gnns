\section{Evaluation Design}
\label{sec:experimental_design}

We design a series of experiments to explore the performance bottleneck in training graph neural networks.
We first introduce the experimental setting in Section~\ref{sec:experimental_env} and then give out our experimental scheme in Section~\ref{sec:experimental_scheme}.
The evaluation results are presented and analyzed later in Section~\ref{sec:experiment_results}.

\subsection{Experimental Setting}
\label{sec:experimental_env}

\paragraph{Experimental Environment}
All the experiments were conducted in a CentOS 7 Linux server with kernel version 3.10.0.
The server had 40 cores and 90 GB main memory.
The server was equipped with an NVIDIA Tesla T4 GPU with 16GB GDDR6 memory.
For the software environment, we adopted Python 3.7.7, PyTorch 1.5.0, and CUDA 10.1.
We implemented all the GNNs with PyTorch Geometric 1.5.0.

\paragraph{Dataset}
We used six real-world graph datasets as listed in \tablename~\ref{tab:dataset_overview} that were popular in the GNN accuracy evaluation \cite{yang2016_revisiting_semisupervised, zeng2020_graphsaint, shchur2018_pitfall_of_gnn}.
For directed graphs, PyG converts them into undirected ones during the data loading.
Thus, the average degree of a directed graph $\bar{d}=\frac{2|\mathcal{E}|}{|\mathcal{V}|}$.
For an undirected graph, $\mathcal{E}$ already contains two-direction edges and $\bar{d}=\frac{|\mathcal{E}|}{|\mathcal{V}|}$.
For the \texttt{cam} dataset, we generated random dense feature vectors.
We also used random graphs generated by the R-MAT graph generator \cite{rmat-generator} in the experiments, to explore the effects of graph topological characteristics (like the average degree) on the performance bottleneck.
Input feature vectors of random graphs were random dense vectors with a dimension of 32.
Vertices of random graphs were classified into 10 classes randomly.

\begin{table}
    \centering
    \begin{tabular}{cccccccc}
        \toprule
        Dataset                                                 & $|\mathcal{V}|$ & $|\mathcal{E}|$ & $\bar{d}$ & $dim(\boldsymbol{x})$ & \#Class & Directed \\
        \midrule
        pubmed (pub) \cite{yang2016_revisiting_semisupervised}  & 19,717          & 44,324          & 4.5       & 500                   & 3       & Yes      \\
        amazon-photo (amp) \cite{shchur2018_pitfall_of_gnn}     & 7,650           & 119,081         & 31.1      & 745                   & 8       & Yes      \\
        amazon-computers (amc) \cite{shchur2018_pitfall_of_gnn} & 13,752          & 245,861         & 35.8      & 767                   & 10      & Yes      \\
        coauthor-physics (cph) \cite{shchur2018_pitfall_of_gnn} & 34,493          & 247,962         & 14.4      & 8415                  & 5       & Yes      \\
        flickr (fli) \cite{zeng2020_graphsaint}                 & 89,250          & 899,756         & 10.1      & 500                   & 7       & No       \\
        com-amazon (cam) \cite{yang2012_defining}               & 334,863         & 925,872         & 2.8       & 32                    & 10      & No       \\
        \bottomrule
    \end{tabular}
    \caption{Dataset overview. $\bar{d}$ represents the average vertex degree. $dim(\boldsymbol{x})$ is the dimension of the input feature vector.}
    \label{tab:dataset_overview}
\end{table}

\paragraph{Learning Task}
We used the node classification as the target task in GNNs due to its popularity in real-world applications.
We trained GNNs with the semi-supervised learning setting.
All vertices and their input feature vectors were used, but only parts of the vertices were attached with labels during the training and they were used to calculate the loss and gradients.
The vertices with unseen labels were used in the evaluation phase to evaluate the accuracy of the current parameters.
%Since model parameters of GNNs were not restricted by the topological structure of $\mathcal{G}$, the model learned from the semi-supervised learning can directly extrapolate to unseen vertices.

\paragraph{GNN Implementation}
We implemented the four typical GNNs (GCN, GGNN, GAT, GaAN) with PyTorch Geometric 1.5.0.
To compare the performance characteristics of four GNNs side-by-side, we used a unified GNN structure for them: Input Layer $\rightarrow$ GNN Layer 0 $\rightarrow$ GNN Layer 1 $\rightarrow$ Softmax Layer (to prediction).
The structure was popular in the experimental evaluation of GCN \cite{kipf2017_gcn}, GAT \cite{huang2018_gat} and GaAN \cite{zhang2018_gaan}.
Since a GGNN layer requires the input and output hidden feature vectors have the same dimension, we added two multi-layer perceptron(MLP) layers to transform the dimensions of the input/output feature vectors of the whole GNN: Input Layer $\rightarrow$ MLP $\rightarrow$ GGNN Layer 0 $\rightarrow$ GGNN Layer 1 $\rightarrow$ MLP $\rightarrow$ Softmax Layer.
We stored the dataset and the model parameters on the GPU side.
All the training was conducted on the GPU.

\paragraph{Hyper-parameters}
We use $dim(\boldsymbol{v})$ to denote the dimension of a vector $\boldsymbol{v}$.
We picked the hyper-parameters of GNNs according to their popularity in the original papers.
We used the same set of hyper-parameters for all the datasets. 
Some hyper-parameters like the dimensions of hidden feature vectors were common in the four GNNs and we set them to the same values.
For GCN/GAT/GaAN, we set $\boldsymbol{h}^0_i = \boldsymbol{x}_i$, $dim(\boldsymbol{h}^1_i)=64$, and $dim(\boldsymbol{h}^2_i)=\#Classes$.
For GAT, we set the hyper-parameters according to its paper\cite{huang2018_gat}.
The first GAT layer had 8 heads with the dimension of each head $d^0_{head}=8$. The first GAT layer merged the heads by concatenating.
The second GAT layer used a single head with the dimension $d^1_{head}=d^1_{out}=\#Classes$.
For GGNN, since it uses extra MLP layers to transform the dimensions of the input/output feature vectors, we set $dim(\boldsymbol{h}^0_i) = dim(\boldsymbol{h}^1_i) = dim(\boldsymbol{h}^2_i) = 64$.
We used 8 heads in the both GaAN layers with $d_a=d_v=8$ and $d_m=64$.

\paragraph{Sampling Techniques}

We picked the neighbor sampler from GraphSAGE \cite{hamilton2017_graphsage} and the cluster sampler from ClusterGCN \cite{chiang2019_cluster_gcn} as the typical sampling techniques respectively.
For the neighbor sampler, we set the neighborhood sample sizes as 25 for GNN Layer 1, and 10 for GNN Layer 0 and set the default batch size as 512 from its paper\cite{hamilton2017_graphsage}.
For the cluster sampler, we partitioned every input graph into 1500 partitions and used 20 partitions per batch according to the parameters used in its paper\cite{chiang2019_cluster_gcn}.

\subsection{Experimental Scheme}
\label{sec:experimental_scheme}

To find out the performance bottleneck in GNN training, we conducted the experimental analysis with four questions.
The answers to those questions will give us a more comprehensive view of the performance characteristics of GNN training.

\begin{itemize}

    \item[Q1] \emph{How do the hyper-parameters affect the training time and the memory usage of a GNN?} (Section~\ref{sec:effects_of_hyper-parameters_on_performance})

          Every GNN has a group of hyper-parameters like the number of GNN layers and the dimensions of hidden feature vectors. The hyper-parameters affect the training time per epoch and the peak memory usage during the training.
          To evaluate their effects, we measured how the training time per epoch and the peak memory usage (of the GPU) changed as we increased the values of the hyper-parameters.
          Through the experiments, we want to verify the validity of the computational complexity analysis in \tablename~\ref{tab:gnn_overview_edge} and \tablename~\ref{tab:gnn_overview_vertex}.
          If the complexity analysis is valid, we can analyze the bottleneck theoretically.

    \item[Q2] \emph{Which stage is the most time-consuming stage in GNN training?} (Section~\ref{sec:training_time_breakdown})

          We can decompose the training time on different levels: layer level, edge/vertex calculation level, and the basic operator level.
          On each level, we decomposed the training time of an epoch into several stages. The most time-consuming stage is the performance bottleneck.
          Optimizing its implementation can significantly reduce the training time.

    \item[Q3] \emph{Which consumes most of memory in GNN training?} (Section~\ref{sec:memory_usage_analysis})

          The limited memory capacity of a GPU is the main factor preventing us from training GNNs on big graphs.
          We measured the peak memory usage of GNN training under different graph scales, input feature dimensions, and average vertex degrees.
          Based on the results, we analyzed which is the most memory-consuming component in a GNN.
          Reducing its memory usage will enable us to train GNNs on bigger graphs under the same memory capacity.

    \item[Q4] \emph{Can the sampling techniques remove the performance bottleneck in GNN training?} (Section~\ref{sec:effects_of_sampling_techniques_on_performance})

          Theoretically, the sampling techniques can significantly reduce the number of graph neurons that participate in the training of a batch.
          Consequently, the training time and the memory usage should also decrease.
          To validate the effectiveness of the sampling techniques, we measured the training time and peak memory usage under different batch sizes.
          If the sampling techniques are effective, they are the keys to conduct GNN training on very big graphs.
          If they are not effective, we want to find out which impairs its efficiency.
\end{itemize}

