\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\newlabel{eq:GAT-sub-layer-1}{{1}{3}{Reviewer \thereviewer }{equation.0.1}{}}
\newlabel{eq:GAT-sub-layer-2}{{2}{3}{Reviewer \thereviewer }{equation.0.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Section 4.1 ``Effects of Hyper-parameters on Performance''}{5}{section*.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Effects of hyper-parameters on the vertex/edge calculation time of GGNN.\relax }}{6}{figure.caption.6}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:compare_effect_of_hyperparameter_on_time}{{1}{6}{Effects of hyper-parameters on the vertex/edge calculation time of GGNN.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Training}}}{6}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Inference}}}{6}{subfigure.1.2}\protected@file@percent }
\newlabel{fig:compare_effect_of_hyperparameter_on_memory_usage_training}{{2a}{7}{Subfigure 2a}{subfigure.2.1}{}}
\newlabel{sub@fig:compare_effect_of_hyperparameter_on_memory_usage_training}{{(a)}{a}{Subfigure 2a\relax }{subfigure.2.1}{}}
\newlabel{fig:compare_effect_of_hyperparameter_on_memory_usage_inference}{{2b}{7}{Subfigure 2b}{subfigure.2.2}{}}
\newlabel{sub@fig:compare_effect_of_hyperparameter_on_memory_usage_inference}{{(b)}{b}{Subfigure 2b\relax }{subfigure.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Effects of hyper-parameters on peak memory usage of GAT.\relax }}{7}{figure.caption.7}\protected@file@percent }
\newlabel{fig:compare_effect_of_hyperparameter_on_memory_usage}{{2}{7}{Effects of hyper-parameters on peak memory usage of GAT.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Training}}}{7}{subfigure.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Inference}}}{7}{subfigure.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Section 4.2 ``Time Breakdown Analysis''}{7}{section*.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Time breakdowns on the layer level of GCN.\relax }}{8}{figure.caption.9}\protected@file@percent }
\newlabel{fig:compare_layer_level_time_breakdown}{{3}{8}{Time breakdowns on the layer level of GCN.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Training}}}{8}{subfigure.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Inference}}}{8}{subfigure.3.2}\protected@file@percent }
\newlabel{fig:compare_effect_of_degree_training}{{4a}{8}{Subfigure 4a}{subfigure.4.1}{}}
\newlabel{sub@fig:compare_effect_of_degree_training}{{(a)}{a}{Subfigure 4a\relax }{subfigure.4.1}{}}
\newlabel{fig:compare_effect_of_degree_inference}{{4b}{8}{Subfigure 4b}{subfigure.4.2}{}}
\newlabel{sub@fig:compare_effect_of_degree_inference}{{(b)}{b}{Subfigure 4b\relax }{subfigure.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Effects of the average degree on the edge/vertex calculation time of GCN. Graphs were generated by fixing the number of vertices as 50,000.\relax }}{8}{figure.caption.10}\protected@file@percent }
\newlabel{fig:compare_effect_of_degree}{{4}{8}{Effects of the average degree on the edge/vertex calculation time of GCN. Graphs were generated by fixing the number of vertices as 50,000.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Training}}}{8}{subfigure.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Inference}}}{8}{subfigure.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Time breakdowns on the step level of the edge calculation stage of GCN.\relax }}{9}{figure.caption.11}\protected@file@percent }
\newlabel{fig:compare_time_breakdown_of_edge_calculation}{{5}{9}{Time breakdowns on the step level of the edge calculation stage of GCN.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Training}}}{9}{subfigure.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Inference}}}{9}{subfigure.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Wall-clock training/inference time on different datasets.\relax }}{9}{figure.caption.12}\protected@file@percent }
\newlabel{fig:compare_wall_clock_time_of_training_and_inference}{{6}{9}{Wall-clock training/inference time on different datasets.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\texttt {amc}}}}{9}{subfigure.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\texttt {amp}}}}{9}{subfigure.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {\texttt {fli}}}}{9}{subfigure.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Top 5 time-consuming basic operators of typical GNNs. The time proportion of each basic operator was averaged over all datasets with the error bar indicating the maximum and the minimum.\relax }}{11}{figure.caption.13}\protected@file@percent }
\newlabel{fig:compare_top_time_consuming_basic_operators}{{7}{11}{Top 5 time-consuming basic operators of typical GNNs. The time proportion of each basic operator was averaged over all datasets with the error bar indicating the maximum and the minimum.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {GCN, Training}}}{11}{subfigure.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {GCN, Inference}}}{11}{subfigure.7.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {GGNN, Training}}}{11}{subfigure.7.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {GGNN, Inference}}}{11}{subfigure.7.4}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {GAT, Training}}}{11}{subfigure.7.5}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {GAT, Inference}}}{11}{subfigure.7.6}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {GaAN, Training}}}{11}{subfigure.7.7}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(h)}{\ignorespaces {GaAN, Inference}}}{11}{subfigure.7.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Section 4.3 ``Memory Usage Analysis''}{12}{section*.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Memory expansion ratios of typical GNNs.\relax }}{12}{figure.caption.15}\protected@file@percent }
\newlabel{fig:compare_memory_expasion_ratio}{{8}{12}{Memory expansion ratios of typical GNNs.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Training}}}{12}{subfigure.8.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Inference}}}{12}{subfigure.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Section 4.4 ``Effects of Sampling Techniques on Performance''}{12}{section*.16}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Characteristics of the sampled subgraphs produced by the inference sampler under different relative batch sizes.\relax }}{13}{figure.caption.17}\protected@file@percent }
\newlabel{fig:sampled_graph_size}{{9}{13}{Characteristics of the sampled subgraphs produced by the inference sampler under different relative batch sizes.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Average degree}}}{13}{subfigure.9.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Number of edges}}}{13}{subfigure.9.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Inference time per batch breakdown under different batch sizes.\relax }}{13}{figure.caption.18}\protected@file@percent }
\newlabel{fig:time_breakdown_of_inference_sampler}{{10}{13}{Inference time per batch breakdown under different batch sizes.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Batch Size = 1024}}}{13}{subfigure.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Batch Size = 2048}}}{13}{subfigure.10.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Effects of hyper-parameters on accuracy of the typical GNNs.\relax }}{16}{figure.caption.20}\protected@file@percent }
\newlabel{fig:exp_hyperparameter_accuracy}{{11}{16}{Effects of hyper-parameters on accuracy of the typical GNNs.\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {GCN}}}{16}{subfigure.11.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {GGNN}}}{16}{subfigure.11.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {GAT}}}{16}{subfigure.11.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {GaAN}}}{16}{subfigure.11.4}\protected@file@percent }
\citation{hamilton2017_graphsage}
\citation{chen2018_fastgcn}
\citation{chiang2019_cluster_gcn}
\citation{zeng2020_graphsaint}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Best accuracy that each GNN achieved on different datasets.\relax }}{17}{figure.caption.21}\protected@file@percent }
\newlabel{fig:exp_hyperparameter_on_accuracy_alg_contrast}{{12}{17}{Best accuracy that each GNN achieved on different datasets.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Test accuracy under different batch sizes of the neighbor sampler. FULL means that the full graph participated in the training.\relax }}{18}{figure.caption.22}\protected@file@percent }
\newlabel{fig:exp_sampling_relative_batch_size_accuracy_graphsage}{{13}{18}{Test accuracy under different batch sizes of the neighbor sampler. FULL means that the full graph participated in the training.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\texttt {amp}}}}{18}{subfigure.13.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\texttt {amc}}}}{18}{subfigure.13.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {\texttt {fli}}}}{18}{subfigure.13.3}\protected@file@percent }
\newlabel{fig:exp_cluster_sampling_accuracy_on_amp}{{14a}{18}{Subfigure 14a}{subfigure.14.1}{}}
\newlabel{sub@fig:exp_cluster_sampling_accuracy_on_amp}{{(a)}{a}{Subfigure 14a\relax }{subfigure.14.1}{}}
\newlabel{fig:exp_cluster_sampling_accuracy_on_amc}{{14b}{18}{Subfigure 14b}{subfigure.14.2}{}}
\newlabel{sub@fig:exp_cluster_sampling_accuracy_on_amc}{{(b)}{b}{Subfigure 14b\relax }{subfigure.14.2}{}}
\newlabel{fig:exp_cluster_sampling_accuracy_on_fli}{{14c}{18}{Subfigure 14c}{subfigure.14.3}{}}
\newlabel{sub@fig:exp_cluster_sampling_accuracy_on_fli}{{(c)}{c}{Subfigure 14c\relax }{subfigure.14.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Test accuracy under different batch sizes of the cluster sampler. FULL means that the full graph participated in the training.\relax }}{18}{figure.caption.23}\protected@file@percent }
\newlabel{fig:exp_sampling_relative_batch_size_accuracy_cluster}{{14}{18}{Test accuracy under different batch sizes of the cluster sampler. FULL means that the full graph participated in the training.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\texttt {amp}}}}{18}{subfigure.14.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\texttt {amc}}}}{18}{subfigure.14.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {\texttt {fli}}}}{18}{subfigure.14.3}\protected@file@percent }
