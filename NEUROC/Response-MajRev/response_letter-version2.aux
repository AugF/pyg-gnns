\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Frequently-used Symbols\relax }}{2}{table.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:symbols}{{1}{2}{Frequently-used Symbols\relax }{table.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comparison of wall-clock training time and inference time on different datasets.\relax }}{4}{figure.caption.5}\protected@file@percent }
\newlabel{fig:compare_wall_clock_time_of_training_and_inference}{{1}{4}{Comparison of wall-clock training time and inference time on different datasets.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\texttt {amc}}}}{4}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\texttt {amp}}}}{4}{subfigure.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {\texttt {fli}}}}{4}{subfigure.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Top 5 time-consuming basic operators of GCN. The time proportion of each basic operator is averaged over all datasets with the error bar indicating the maximum and the minimum.\relax }}{4}{figure.caption.6}\protected@file@percent }
\newlabel{fig:compare_top_basic_operators}{{2}{4}{Top 5 time-consuming basic operators of GCN. The time proportion of each basic operator is averaged over all datasets with the error bar indicating the maximum and the minimum.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Training}}}{4}{subfigure.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Inference}}}{4}{subfigure.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Memory expansion ratios of typical GNNs.\relax }}{5}{figure.caption.7}\protected@file@percent }
\newlabel{fig:compare_memory_expasion_ratio}{{3}{5}{Memory expansion ratios of typical GNNs.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Training}}}{5}{subfigure.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Inference}}}{5}{subfigure.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Inference time per batch breakdown under the batch size of 2048.\relax }}{6}{figure.caption.8}\protected@file@percent }
\newlabel{fig:time_breakdown_of_inference_sampler}{{4}{6}{Inference time per batch breakdown under the batch size of 2048.\relax }{figure.caption.8}{}}
\citation{shchur2018_pitfall_of_gnn,zeng2020_graphsaint}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Effects of hyper-parameters on accuracy of GaAN.\relax }}{7}{figure.caption.10}\protected@file@percent }
\newlabel{fig:effect_of_hyper_parameter_on_accuracy_of_gaan}{{5}{7}{Effects of hyper-parameters on accuracy of GaAN.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Best accuracy that each GNN achieves on different datasets.\relax }}{8}{figure.caption.11}\protected@file@percent }
\newlabel{fig:exp_hyperparameter_on_accuracy_alg_contrast}{{6}{8}{Best accuracy that each GNN achieves on different datasets.\relax }{figure.caption.11}{}}
\citation{zeng2020_graphsaint}
\newlabel{fig:exp_graphsage_sampling_accuracy_on_amp}{{7a}{9}{Subfigure 7a}{subfigure.7.1}{}}
\newlabel{sub@fig:exp_graphsage_sampling_accuracy_on_amp}{{(a)}{a}{Subfigure 7a\relax }{subfigure.7.1}{}}
\newlabel{fig:exp_graphsage_sampling_accuracy_on_amc}{{7b}{9}{Subfigure 7b}{subfigure.7.2}{}}
\newlabel{sub@fig:exp_graphsage_sampling_accuracy_on_amc}{{(b)}{b}{Subfigure 7b\relax }{subfigure.7.2}{}}
\newlabel{fig:exp_graphsage_sampling_accuracy_on_fli}{{7c}{9}{Subfigure 7c}{subfigure.7.3}{}}
\newlabel{sub@fig:exp_graphsage_sampling_accuracy_on_fli}{{(c)}{c}{Subfigure 7c\relax }{subfigure.7.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Test accuracy under different batch sizes of the neighbor sampler. FULL means that the full graph participated in the training.\relax }}{9}{figure.caption.12}\protected@file@percent }
\newlabel{fig:exp_sampling_relative_batch_size_accuracy_graphsage}{{7}{9}{Test accuracy under different batch sizes of the neighbor sampler. FULL means that the full graph participated in the training.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\texttt {amp}}}}{9}{subfigure.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\texttt {amc}}}}{9}{subfigure.7.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {\texttt {fli}}}}{9}{subfigure.7.3}\protected@file@percent }
\newlabel{fig:exp_cluster_sampling_accuracy_on_amp}{{8a}{9}{Subfigure 8a}{subfigure.8.1}{}}
\newlabel{sub@fig:exp_cluster_sampling_accuracy_on_amp}{{(a)}{a}{Subfigure 8a\relax }{subfigure.8.1}{}}
\newlabel{fig:exp_cluster_sampling_accuracy_on_amc}{{8b}{9}{Subfigure 8b}{subfigure.8.2}{}}
\newlabel{sub@fig:exp_cluster_sampling_accuracy_on_amc}{{(b)}{b}{Subfigure 8b\relax }{subfigure.8.2}{}}
\newlabel{fig:exp_cluster_sampling_accuracy_on_fli}{{8c}{9}{Subfigure 8c}{subfigure.8.3}{}}
\newlabel{sub@fig:exp_cluster_sampling_accuracy_on_fli}{{(c)}{c}{Subfigure 8c\relax }{subfigure.8.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Test accuracy under different batch sizes of the cluster sampler. FULL means that the full graph participated in the training.\relax }}{9}{figure.caption.13}\protected@file@percent }
\newlabel{fig:exp_sampling_relative_batch_size_accuracy_cluster}{{8}{9}{Test accuracy under different batch sizes of the cluster sampler. FULL means that the full graph participated in the training.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\texttt {amp}}}}{9}{subfigure.8.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\texttt {amc}}}}{9}{subfigure.8.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {\texttt {fli}}}}{9}{subfigure.8.3}\protected@file@percent }
\bibstyle{elsarticle}
\bibdata{../gnnref.bib}
\bibcite{chiang2019_cluster_gcn}{{1}{2019}{{Chiang et~al.}}{{}}}
\bibcite{hamilton2017_graphsage}{{2}{2017}{{Hamilton et~al.}}{{}}}
\bibcite{shchur2018_pitfall_of_gnn}{{3}{2018}{{Shchur et~al.}}{{}}}
\bibcite{zeng2020_graphsaint}{{4}{2020}{{Zeng et~al.}}{{}}}
